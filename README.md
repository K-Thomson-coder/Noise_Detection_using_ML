# ğŸ”Š Noise vs Silence Classification

A real-time audio classification app that distinguishes between noise and silence using a custom-trained RandomForestClassifier. Built with Python, Librosa, Scikit-learn, and Streamlit, the app features interactive audio recording, visual feedback (waveform and spectrogram), and a clean user interface.


---

## ğŸ“ Project Structure
```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ converted/                   # Converted .wav files from raw sources
â”‚   â”œâ”€â”€ raw/                         # Original audio files (e.g., .webm)
â”‚   â”œâ”€â”€ wav/                         # Labeled audio files (noise/silence)
â”‚   â””â”€â”€ features.csv                 # Extracted MFCC features

â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ model.pkl                    # Trained ML model
â”‚   â””â”€â”€ scaler.pkl                   # Scaler for feature normalization

â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ RandomForest.ipynb           # Notebook for training/testing

â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ convert_webm_to_wav_ffmpeg.py   # Convert .webm to .wav
â”‚   â”œâ”€â”€ featureExtraction.py            # Extract MFCCs from audio
â”‚   â”œâ”€â”€ file.py                         # Save/load functions
â”‚   â””â”€â”€ add_bg_image.py                 # Custom Streamlit background loader

â”œâ”€â”€ Noise_Detector.py               # Main Streamlit app
â”œâ”€â”€ README.md                       # Project documentation [You are here]
â”œâ”€â”€ requirements.txt                # Required Python packages

```
---

## ğŸš€ Features

ğŸ™ Real-time audio recording with microphone<br>
ğŸ“ˆ Waveform and spectrogram visualization<br>
ğŸ§  RandomForestClassifier trained on MFCC features<br>
ğŸ› Duration control and background customization<br>
ğŸ§ª Live predictions and class probability output<br>
ğŸ§© Modular and user-friendly interface with collapsible settings


---

## âš™ Requirements

Install dependencies:
```
pip install -r requirements.txt
```
Make sure ffmpeg is installed and your Python version is compatible.


---

## ğŸ›  How to Use

1. Prepare dataset

    Place .wav files into:
```
    data/wav/noise/
    data/wav/silence/
```

2. Extract features

```
    python scripts/featureExtraction.py
```

3. Train the model

    Open the Jupyter notebook:
```
    jupyter notebook notebooks/RandomForest.ipynb
```
4. Run the app

```
    streamlit run Noise_Detector.py
```

---

## ğŸ“š Learning Goals
<ul>
    <li>Audio feature extraction using MFCC (Librosa)</li>
    <li>Model training with scikit-learn</li>
    <li>Live audio input handling</li>
    <li>Building a reactive UI with Streamlit</li>
    <li>Custom UI styling with CSS and layout tweaks</li>
</ul>

---

## ğŸ“¦ Dependencies
```
librosa

numpy

pandas

scikit-learn

sounddevice

streamlit

moviepy

ffmpeg
```

(See requirements.txt for full list)

---

## ğŸ¨ Custom Background (Optional)

This app includes an optional custom background feature using an image stored in an assets/ folder.

To enable the background styling:

1. Create a folder named assets/ in the project root.  
2. Add your background image inside it, e.g., assets/background.png.  
3. The app will automatically load the image if it exists.

> ğŸ”’ *Note:* The assets/ folder is excluded from the repository to keep it lightweight. You can customize your background by adding your own image.


---

âœ Credits

Built with curiosity, sound, and Python
by ***Kangujam Thomson Singh***


---